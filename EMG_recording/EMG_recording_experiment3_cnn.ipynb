{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MulticlassConfusionMatrix' from 'torchmetrics.classification' (/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/classification/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-c3c9f02af096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MulticlassConfusionMatrix' from 'torchmetrics.classification' (/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/classification/__init__.py)"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "import os\n",
    "\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_actions(path):\n",
    "    files = os.listdir(path)\n",
    "    num_files = len(files)\n",
    "    segment_size = 2000\n",
    "    data = np.zeros((num_files, segment_size), dtype=np.int16)\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        file = files[i]\n",
    "        if \".DS_Store\" not in file:\n",
    "            with open(path + \"/\" +file, \"rb\") as f:\n",
    "                signal = [float(line.strip()) for line in f]\n",
    "                data[i, :] = signal\n",
    "        else:\n",
    "            continue        \n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def wave_data_loader():\n",
    "    flexion = read_actions('./flexion' + \"/action/\")\n",
    "    openhand = read_actions('./openhand' + \"/action/\")\n",
    "    punch = read_actions('./punch' + \"/action/\")\n",
    "    rest1 = read_actions('./flexion' + \"/rest/\")\n",
    "    rest2 = read_actions('./openhand' + \"/rest/\")\n",
    "    rest3 = read_actions('./punch' + \"/rest/\")\n",
    "    \n",
    "    all_data = np.vstack((flexion,\n",
    "                          openhand,\n",
    "                          punch,\n",
    "#                           rest1,\n",
    "#                           rest2,\n",
    "                          rest3))\n",
    "    label = np.hstack(([1]*flexion.shape[0],\n",
    "                      [2]*openhand.shape[0],\n",
    "                      [3]*punch.shape[0],\n",
    "#                       [0]*rest1.shape[0],\n",
    "#                       [0]*rest2.shape[0],\n",
    "                      [0]*rest3.shape[0]))\n",
    "    label = np.transpose(label)\n",
    "#     label_multiClass = np.zeros((label.size,4))\n",
    "#     for i in range(label.size):\n",
    "#         label_multiClass[i,label[i]] = 1\n",
    "    return all_data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class WaveformDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.signals, self.labels = wave_data_loader()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.signals[idx]\n",
    "        label = self.labels[idx]\n",
    "        return signal, label\n",
    "\n",
    "    \n",
    "    \n",
    "class WaveformCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaveformCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=1, \n",
    "                                             out_channels=8, \n",
    "                                             kernel_size=7, \n",
    "                                             stride=1, \n",
    "                                             padding=3),\n",
    "                                   nn.BatchNorm1d(8),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "                                   nn.Dropout(0.3))\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=8, \n",
    "                                             out_channels=16, \n",
    "                                             kernel_size=5, \n",
    "                                             stride=1, \n",
    "                                             padding=2),\n",
    "                                   nn.BatchNorm1d(16),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(kernel_size=4, stride=4),\n",
    "                                   nn.Dropout(0.3))\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(int(16 * 2000/4/4), 16),\n",
    "                                 nn.Dropout(0.4),\n",
    "                                 nn.ReLU())\n",
    "#         \n",
    "        self.fc2 = nn.Linear(16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Trains the specified model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        signal, label = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(signal.float())\n",
    "#         print(output)\n",
    "#         print(label)\n",
    "        loss = nn.CrossEntropyLoss()(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(signal), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    # Test the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "        for signals, labels in test_loader:\n",
    "            test_output = model(signals.float())\n",
    "            _, pred_y = torch.max(test_output.data, 1)\n",
    "#             pred_y = torch.max(test_output, 1)[1].data.squeeze()  # the same function as above\n",
    "            total += labels.size(0)\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            \n",
    "    print(f'Accuracy of the CNN on the {total} signals: {100 * correct // total} %')\n",
    "#     print(correct)\n",
    "#     print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WaveformDataset()\n",
    "train_set, test_set = random_split(dataset, [int(0.8*len(dataset)), int(0.2*len(dataset))+1])\n",
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=10, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WaveformCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/860 (0%)]\tLoss: 1.605456\n",
      "Train Epoch: 1 [200/860 (23%)]\tLoss: 0.770070\n",
      "Train Epoch: 1 [400/860 (47%)]\tLoss: 0.932734\n",
      "Train Epoch: 1 [600/860 (70%)]\tLoss: 0.664290\n",
      "Train Epoch: 1 [800/860 (93%)]\tLoss: 0.741167\n",
      "Train Epoch: 2 [0/860 (0%)]\tLoss: 1.181676\n",
      "Train Epoch: 2 [200/860 (23%)]\tLoss: 1.367007\n",
      "Train Epoch: 2 [400/860 (47%)]\tLoss: 1.172551\n",
      "Train Epoch: 2 [600/860 (70%)]\tLoss: 0.844006\n",
      "Train Epoch: 2 [800/860 (93%)]\tLoss: 0.923556\n",
      "Train Epoch: 3 [0/860 (0%)]\tLoss: 0.815863\n",
      "Train Epoch: 3 [200/860 (23%)]\tLoss: 0.494703\n",
      "Train Epoch: 3 [400/860 (47%)]\tLoss: 1.040463\n",
      "Train Epoch: 3 [600/860 (70%)]\tLoss: 0.745464\n",
      "Train Epoch: 3 [800/860 (93%)]\tLoss: 0.549107\n",
      "Train Epoch: 4 [0/860 (0%)]\tLoss: 0.560904\n",
      "Train Epoch: 4 [200/860 (23%)]\tLoss: 0.432522\n",
      "Train Epoch: 4 [400/860 (47%)]\tLoss: 0.563852\n",
      "Train Epoch: 4 [600/860 (70%)]\tLoss: 0.591589\n",
      "Train Epoch: 4 [800/860 (93%)]\tLoss: 0.803793\n",
      "Train Epoch: 5 [0/860 (0%)]\tLoss: 0.587805\n",
      "Train Epoch: 5 [200/860 (23%)]\tLoss: 0.724155\n",
      "Train Epoch: 5 [400/860 (47%)]\tLoss: 0.847099\n",
      "Train Epoch: 5 [600/860 (70%)]\tLoss: 0.746940\n",
      "Train Epoch: 5 [800/860 (93%)]\tLoss: 0.815849\n",
      "Train Epoch: 6 [0/860 (0%)]\tLoss: 0.989035\n",
      "Train Epoch: 6 [200/860 (23%)]\tLoss: 0.532421\n",
      "Train Epoch: 6 [400/860 (47%)]\tLoss: 0.814531\n",
      "Train Epoch: 6 [600/860 (70%)]\tLoss: 0.935878\n",
      "Train Epoch: 6 [800/860 (93%)]\tLoss: 1.052341\n",
      "Train Epoch: 7 [0/860 (0%)]\tLoss: 0.838876\n",
      "Train Epoch: 7 [200/860 (23%)]\tLoss: 0.484764\n",
      "Train Epoch: 7 [400/860 (47%)]\tLoss: 1.004820\n",
      "Train Epoch: 7 [600/860 (70%)]\tLoss: 0.846474\n",
      "Train Epoch: 7 [800/860 (93%)]\tLoss: 0.761433\n",
      "Train Epoch: 8 [0/860 (0%)]\tLoss: 0.954402\n",
      "Train Epoch: 8 [200/860 (23%)]\tLoss: 0.626754\n",
      "Train Epoch: 8 [400/860 (47%)]\tLoss: 0.900495\n",
      "Train Epoch: 8 [600/860 (70%)]\tLoss: 0.433762\n",
      "Train Epoch: 8 [800/860 (93%)]\tLoss: 0.894163\n",
      "Train Epoch: 9 [0/860 (0%)]\tLoss: 0.906450\n",
      "Train Epoch: 9 [200/860 (23%)]\tLoss: 0.780588\n",
      "Train Epoch: 9 [400/860 (47%)]\tLoss: 0.956919\n",
      "Train Epoch: 9 [600/860 (70%)]\tLoss: 0.768888\n",
      "Train Epoch: 9 [800/860 (93%)]\tLoss: 0.740462\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(1, 10):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save parameter\n",
    "# PATH = r'./model_parameter/dropout.pth'\n",
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the CNN on the 216 signals: 67 %\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "test(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the CNN on the 860 signals: 66 %\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "test(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计各类的数据量 尽量balance\n",
    "_, label = wave_data_loader()\n",
    "(label==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "def confusion_matrix(model, test_loader):\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "        for signals, labels in test_loader:\n",
    "            outputs = model(signals.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())    \n",
    "    \n",
    "    metric = MulticlassConfusionMatrix(num_classes=4)\n",
    "    cf_matrix = metric(y_pred, y_true)\n",
    "    \n",
    "\n",
    "    class_names = ('rest', 'flexion', 'openhand', 'punch')\n",
    " \n",
    "    # Create pandas dataframe\n",
    "    dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Create heatmap\n",
    "    sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
    "\n",
    "    plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "\n",
    "    plt.ylabel(\"True Class\"), \n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MulticlassConfusionMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-7c7c48188481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-5d7a7fe92f70>\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassConfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MulticlassConfusionMatrix' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
